tool_parser: "v20250824"

# Client config for the SearchAgent (SFT model)
search_agent_base_url: "http://localhost:30001/v1"
search_agent_model_name: "rl-research/DR-Tulu-8B"
search_agent_tokenizer_name: "Qwen/Qwen3-8B"
search_agent_api_key: "dummy-key"
search_agent_max_tokens: 32000
search_agent_temperature: 1.0
search_agent_max_tool_calls: 10

# Client config for the browse/reader agent (general model)
use_browse_agent: false
browse_agent_base_url: "http://localhost:30002/v1"
browse_agent_model_name: "Qwen/Qwen3-8B" # This should be the same name when you launch the VLLM backend. 
browse_agent_tokenizer_name: "Qwen/Qwen3-8B" # But this should the name when you load it from the huggingface model hub. 
browse_agent_api_key: "dummy-key"
browse_agent_max_tokens: 32000
browse_agent_temperature: 0.3

# Search tool configuration
number_documents_to_search: 10
search_timeout: 180

# Browse tool configuration
browse_tool_name: "jina" #"crawl4ai"
browse_timeout: 180
browse_max_pages_to_fetch: 10
browse_context_char_length: 6000
